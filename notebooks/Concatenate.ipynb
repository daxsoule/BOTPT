{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read all Central BPR - import datafiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import hvplot.pandas\n",
    "# import numpy as np\n",
    "# import matplotlib.dates as dates\n",
    "# import warnings\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import hvplot.pandas\n",
    "import numpy as np\n",
    "import matplotlib.dates as dates\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import holoviews as hv\n",
    "from holoviews import dim, opts\n",
    "import hvplot.dask\n",
    "hv.extension('bokeh')\n",
    "import glob, os\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "def inc(x):\n",
    "    sleep(1)\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    sleep(1)\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "def dateparse (date_string):\n",
    "    return datetime.datetime.strptime(date_string, '%m/%d/%Y %H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/jovyan/data/bpr/Axial_Deformation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Central BPR files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path = '/home/jovyan/data/bpr/Axial_Deformation/center/' # use your path\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"*.proc\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f, parse_dates=True, date_parser=dateparse, index_col='Date',\n",
    "                       dtype = {'Date': object,'RawDep': np.float64,\n",
    "                                'Temp': np.float64, 'DriftCorrRawDep': np.float64,\n",
    "                                'SpotlDep': np.float64, 'DriftCorrSpotlDep': np.float64,\n",
    "                                'LPFDep,DriftCorrLPFDep': np.float64}) for f in all_files)\n",
    "\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=False)\n",
    "df_center   = concatenated_df.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_center.index = pd.to_datetime(df_south.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_center.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read BPR South files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "path = '/home/jovyan/data/bpr/Axial_Deformation/south/' # use your path\n",
    "\n",
    "all_files = glob.glob(os.path.join(path, \"*.proc\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "\n",
    "df_from_each_file = (pd.read_csv(f, parse_dates=True, date_parser=dateparse, index_col='Date',\n",
    "                       dtype = {'Date': object,'RawDep': np.float64,\n",
    "                                'Temp': np.float64, 'DriftCorrRawDep': np.float64,\n",
    "                                'SpotlDep': np.float64, 'DriftCorrSpotlDep': np.float64,\n",
    "                                'LPFDep,DriftCorrLPFDep': np.float64}) for f in all_files)\n",
    "\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=False)\n",
    "df_south   = concatenated_df.sort_values(by='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_south.index = pd.to_datetime(df_south.index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_south.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.merge(df_center, df_south,how='inner', indicator=True, left_index=True, right_index=True, suffixes=('_C', '_S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge = pd.DataFrame()\n",
    "df_merge = test[test['_merge'] == 'both']\n",
    "del df_merge['_merge']\n",
    "df_merge['RawDep'] = (df_gravMerge['RawDep_C'] + df_gravMerge['RawDep_S'])/2\n",
    "df_merge['Temp'] = (df_gravMerge['Temp_C'] + df_gravMerge['Temp_S'])/2\n",
    "df_merge['DriftCorrRawDep'] = (df_gravMerge['DriftCorrRawDep_C'] + df_gravMerge['DriftCorrRawDep_S'])/2\n",
    "df_merge['SpotlDep'] = (df_gravMerge['SpotlDep_C'] + df_gravMerge['SpotlDep_S'])/2\n",
    "df_merge['DriftCorrSpotlDep'] = (df_gravMerge['DriftCorrSpotlDep_C'] + df_gravMerge['DriftCorrSpotlDep_S'])/2\n",
    "del df_merge['RawDep_C']\n",
    "del df_merge['Temp_C']\n",
    "del df_merge['DriftCorrRawDep_C']\n",
    "del df_merge['velocidad_C']\n",
    "del df_merge['fecha_telegrama_C']\n",
    "del df_merge['RawDep_S']\n",
    "del df_merge['Temp_S']\n",
    "del df_merge['DriftCorrRawDep_S']\n",
    "del df_merge['velocidad_S']\n",
    "del df_merge['fecha_telegrama_S']\n",
    "del df_merge['status']\n",
    "df_gravMerge.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
